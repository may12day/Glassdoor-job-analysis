Title,Location,Company,Rating,Description
Data Analyst,Bengaluru,Target, 4.0,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning,Bengaluru,Accenture, 3.9,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Data Scientist - Machine Learning,Bengaluru,HP Inc., 4.1,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Software Engineer - ,Mumbai,Saavn, 4.4,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Engineer - III,Hyderabad,Phenom People , 4.5,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
"Customer Success Manager, Enterprise",New Delhi,Udacity, 3.2,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
"Senior Data Engineer - Python, Machine Learning, Spark, REST API",Gurgaon,American Express, 3.9,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Engineer,Pune,Amdocs, 3.7,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
,Pune,Credit Suisse, 3.6,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Assistant Manager - Machine learning,Gurgaon,Genpact, 3.5,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Sr Data Scientist,Bengaluru,Target, 4.0,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Data Scientist,Hyderabad,Neustar,None,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Digital ,Bengaluru,IBM, 3.7,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Lead Engineer,Bengaluru,Target, 4.0,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Data Scientist,Mumbai,Star TV Network, 3.6,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning,Noida,KiwiTech, 4.0,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Data Science & Machine Learning Architect,Pune,Druva,None,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Sr Software Developer,Bengaluru,Oracle, 3.5,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Data Scientist ,Gurgaon,Mobileum, 3.5,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Data Scientist,Bengaluru,ExxonMobil, 3.8,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Workfusion Machine Learning Engineer,Bengaluru,Luxoft,None,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
,Mumbai,Camsdata, 4.5,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Internship,Bengaluru,TechCiti Technologies Pvt.Ltd., 3.2,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Engineer,Noida,Magic Software, 3.5,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning,Gurgaon,AgNext, 3.5,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
MACHINE LEARNING ENGINEER,Bengaluru,Neva Ventures, 4.3,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Engineer,Bengaluru,Cargill, 3.8,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Scientist,New Delhi,hike, 4.4,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Applied Research Scientist Search & Sensei Team,Noida,Adobe, 4.2,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
"SDE - Machine Learning, Traffic Quality",Bengaluru,Amazon, 4.1,"Description:  About us:  Target is an iconic brand, a Fortune 50 company and one of Americas leading retailers.  Behind one of the worlds best loved brands is a uniquely capable and brilliant team ofdata scientists, engineers and analysts. The Target Data Science & Analytics team creates thetools and data productsto sustainably educate and enable our business partners to make greatdata-based decisions. We help develop the technology that personalizes the guest experience, fromproduct recommendationsto relevant ad content. Were also the source of the data and analytics behind Targets Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measureor A/B testopportunitiesthat continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.  A role withData Science and Analytics (DSA) means beinga partof the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.  As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.  Core responsibilities are described within this job description. Job duties may change at any time due to business needs.  About You: B.Tech / B.E. or equivalent experience 1+ years of relevant experience Hands-on experience in analytics / data science Understanding of foundational mathematics and statistics Conceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc. Basic SQL skills Strong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise Exposure to R, Python, Hive, or other open source languages preferable Big data experience preferable Qualifications:"
Machine Learning Engineer,Bengaluru,Paytm, 3.6,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
HP Labs Senior Machine Learning Research Scientist,Bengaluru,HP Inc., 4.1,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Engineer,Pune,Foghorn Systems,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning,Bengaluru,3d-ip semiconductors,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Engineer,Bengaluru,Ignitarium Technology Solutions, 4.6,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Developer Technology Engineer - AI,Bengaluru,NVIDIA, 4.4,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning,New Delhi,Chariot Tech, 4.7,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning,Ahmedabad,Technostacks, 5.0,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Engineer,Bengaluru,Johnson Controls,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Software Intern,Hyderabad,Apple, 4.6,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Data Scientist,Bengaluru,Intuit, 4.1,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Researcher,Gurgaon,OYO Rooms, 3.5,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning,Pune,Zensar Technologies, 3.5,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Engineer,Bengaluru,GO-JEK, 4.0,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Engineer,Chennai,Mad Street Den, 4.5,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Engineer,Hyderabad,DataRobot,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
,Mumbai,Viteos Capital Market Services, 4.1,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning,Bengaluru,Digital Horizons Technology & Media Services Private Limited, 2.9,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Intern,Pune,Acellere GmbH,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning,Gurgaon,Think Future Technologies, 3.7,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Internship,Ahmedabad,Moodcafe,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Engineer,Pune,Helpshift,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning,Bengaluru,Diverse Lynx India, 4.2,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
AI/Machine Learning Engineer,Hyderabad,TCPWave, 5.0,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Data Scientist - Machine Learning Engineer,Pune,Aera Technology,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning,Ahmedabad,Anri Solutions HR Services Private Limited, 2.7,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Machine Learning Engineer,Chennai,e-con Systems,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Data scientist - Machine Learning,Chennai,Ford Motor Company,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Senior Software Engineer (Machine Learning/Java),Pune,Qualys, 2.3,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
Data Scientist (Machine Learning),Barabanki,Escon Info Systems,None,"Skills Proficiency using R / Python for predictive modelling, pattern recognition, and algorithm prototyping. Can apply probability models and machine learning approaches to solving complex problems Adept at data manipulation, transformation, and decomposition Identify key variables, parameters and elements defining a problem or its solution. Can distill highly technical knowledge and techniques to collaborators outside the problem domain. Java and/or Scala programming is a plus Experience Previous exposure to (i) Large datasets with low to mid level analytical complexity (ii) Small datasets with high analytical complexity (iii) Data structures containing complex relationship patterns (iv) Data with low signal to noise (v) Unstructured Data Algorithm development with application to solving human problems. Previous involvement in software development and/or distributed computing projects is a plus Background Advanced Degree or equivalent experience with a focus in one or more areas involving Mathematics, Physics, Computer Science, Probability Modelling, Machine Learning, Algorithm Design, Computational Finance, or Bioinformatics Background in mobile or e-commerce data is a plus"
"Software Engineer, Machine Learning",Hyderabad,Google,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Scientist - Machine Learning,Pune,Xcaliber Infotech,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Science (Jupyter/Azure ML/MatLab),Hyderabad,Accenture, 3.9,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Senior ,Mumbai,Lynk,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Senior Manager - Machine Learning,Gurgaon,Genpact, 3.5,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning,New Delhi,Untrodden Labs,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning,Hyderabad,QuEST Global, 3.2,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning,Bengaluru,Pricyfy Technologies, 2.9,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Engineer,Bengaluru,Involvio India,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data scientist - Machine Learning,Chennai,FGBS- Ford Global Business Services,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Engineer,New Delhi,Tradeindia.com,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning,Bengaluru,New Era India, 3.9,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Lead Engineer,Bengaluru,Johnson Controls,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning,Bengaluru,Bayes Labs,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Scientist,Pune,Honeywell, 3.8,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Engineer,Bengaluru,Observe.AI,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Assistant ,Mumbai,citius tech, 3.7,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Scientist,New Delhi,Boston Consulting Group, 3.8,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning,New Delhi,mapmyindia,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
SOFTWARE ENGINEER DATA & MACHINE LEARNING,Pune,Velotio Technologies, 4.8,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Scientist,Noida,Adobe, 4.2,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Scientist,Hyderabad,Phenom People, 4.5,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Engineer,Jaipur,Atrium,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Scientist - Machine Learning,Gurgaon,PropTiger | Housing,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Scientist - Machine Learning,Visakhapatnam,Amzur Infotech Private Limited,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
NLP Machine Learning Engineer,Chennai,Contract Wrangler Inc.,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
,Mumbai,Beatmy Salary,None,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Engineer,Pune,Pratiti Technologies, 4.0,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Engineer,Bengaluru,Unbxd Inc, 3.9,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning Engineer - GO-PAY,Bengaluru,GO-JEK, 4.0,"Minimum qualifications: Bachelor's degree in Computer Science, or related technical field, or equivalent work experience. 5 years of relevant work experience. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Research or Industry experience in Artificial Intelligence, Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep Learning. Preferred qualifications: MA/MS degree or PhD in Computer Science, or related technical field. Knowledge of and experience in Computer Science, with a focus on data structures, algorithms, and software design. About the job  We're looking for engineers who are passionate about developing powerful and efficient apps and platforms that work well for people coming online for the first time through lower end mobile devices, often with slower or limited data connections. Were looking for people with a keen interest in mobile development, working within a team, in fast-paced and startup-like environment, and who are able to collaborate with other teams looking the solve for the same challenges.  Google is passionate about organizing the worlds information and making it universally accessible and useful. As more Internet users come online around the world, we aim to address the needs of people in developing countries, including India, Indonesia and the Philippines. The needs and computing paradigm of these users are uniquely differentiated and we look forward to providing them with the best products and services to suit their growing digital lives.  As part of this effort, you will work closely with engineering teams around the world to build great products and features. Responsibilities Design, develop, test, deploy, maintain and improve ML models/infrastructure and software that uses these models. Manage individual project priorities, deadlines and deliverables.  At Google, we dont just accept differencewe celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Machine Learning/Data Scientist,Pune,Forgeahead, 2.7,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning/AI Engineer,Gurgaon,Nimbushire,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Software Engineer-Python/Spark/Machine Learning,Bengaluru,Cisco Systems, 4.1,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Quality Engineer - Machine Learning,Bengaluru,SAP, 4.4,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Data Scientist - Machine Learning,Bengaluru,HP, 4.1,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Engineer,Gurgaon,Uncap Research Labs, 4.0,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Engineer,Chennai,Kinetix Trading Solutions Inc,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
,Mumbai,Truebil.com, 4.0,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Internship,Bengaluru,Digital Horizons Technology & Media Services Private Limited, 2.9,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Researcher ( Consumer),Gurgaon,OYO, 3.5,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
AI Architect - Machine learning,Bengaluru,Zycus, 3.6,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning,New Delhi,RedCarpetUp, 3.7,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning,New Delhi,Agsmartic Technologies Private Limited, 4.5,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Data Scientist,Hyderabad,Amazon, 4.1,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Engineer,Bengaluru,Prodapt SA,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Specialist,Hyderabad,AlienTT,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Engineer,Kolkata,Onometra Technologies Private Limited,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning,Chennai,Concern Infotech,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning-,Noida,Vidooly Media Tech, 4.5,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Artificial Intelligence,Chennai,Accenture, 3.9,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
,Mumbai,Flochat,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Analytics Modeler (Machine Learning),Chennai,Ford Motor Company,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine-Learning Engineer,Pune,Han Digital Solution,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning-Architect,Pune,Wipro Limited, 3.5,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Specialist,Bengaluru,Subex,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Manager Engineering-machine Learning,Pune,Praxis Consultants, 5.0,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning/Data Science,Ahmedabad,Dynamic Elements,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Python expert with Machine Learning background,Bengaluru,Mantra Labs, 3.7,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning Developer,Pune,Beatmy Salary,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning,India,AI Tech Systems,None,"Key Responsibilities: Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities. Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas. Inspire and influence others for continous improvement in every aspect Be hands on in development and execution of predictive analytics and machine learning.  Job Requirements : Minimum two years of experience with Machine Learning technologies Expert in building custom ML algorithms leveraging statistical concepts and ML tools Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models. Understanding & working knowledge in Natural Language Processing & Conceptual modelling. Proficiency in statistical analysis tools (R, Python and SAS). Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification). Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra) Awareness/Experience with big data tools (Hadoop, HDFS & Spark). Experience on AWS/Google machine learning services is a plus. Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)"
Machine Learning,Indore,Cognera Incorporation,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Data Engineer,Hyderabad,Apple, 4.6,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning Development Lead,Hyderabad,Qualcomm,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning,Pune,PSA Cakes,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
"Software Engineer, Machine Learning",Haryana,Pramira Inc,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning,Ahmedabad,Episodiclabs Private Limited,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
,Mumbai,Markytics,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning Expert,Gurgaon,Roposo, 4.6,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning Engineer,Bengaluru,Kruzr,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning Developer,Pune,NLP,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Software Engineer - ,Mumbai,Affinity Global Advertising,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
,Mumbai,ICS Consultancy Services, 4.0,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Data Scientist - NLP Machine Learning,Chandigarh,Jugnoo, 3.4,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning,Bhopal,SJTech Solutions,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Technical Team Member Distributed Data Science & Machine Learning,Kolkata,Agnik, 4.9,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Senior Engineer (Machine Learning),Ahmedabad,Softnautics, 3.6,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Computer Vision,Pune,Accenture, 3.9,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning  PE,Chennai,Rectras, 5.0,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning,Bengaluru,Tookitaki, 4.6,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning,Secunderabad,Vikas Choudhary,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning,New Delhi,Cvision.ai,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Data Scientist,Chennai,Shell, 3.9,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning Internship,New Delhi,Cvision.ai,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
,Ahmedabad,JB Solutions, 5.0,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
"AI/Machine learning-NLP, Deep learning",Bengaluru,Zycus, 3.6,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
,Mumbai,Qrata,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Software Engineer IV- Zendesk,Bengaluru,AppDynamics, 4.4,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning Engineer,Bengaluru,Tookitaki, 4.6,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
,Maharashtra,Tekolutions.ai,None,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
Machine Learning-Lead,Kolkata,Wipro LTD, 3.5,"About the company:  Cognera Incorporation is a young start-up which believes that technology, when combined with simplicity, creates magic. Founded by a group of highly motivated tech-believers, artists and innovators, it is all set to radicalize the entertainment industry using artificial intelligence. Using its research focused and innovative nifty techniques and approaches, it will bring about a phenomenal change in the media industry by building products that use advanced technology, and yet are extremely easy to use.  About the internship:  Selected intern's day to day responsibilities will include : Mining, cleaning and organizing data to be used by various models Building highly scalable and generic deep-learning models Reading and sorting of research papers based on relevance Implementing and experimenting with various cutting-edge deep-learning models Building efficient and multi-threaded applications Automating the build system Contributing to the testing framework  Who can apply: are available for full time (in-office) internship have relevant skills and interests can start the internship between 11th Jul'19 and 10th Aug'19 are available for duration of 2 months have already graduated or are currently in any year of study Females willing to start/restart their career may also apply </p>  Other requirements:  Candidates with experience with classical machine-learning algorithms Candidates with experience with vanilla neural-networks, CNN and/or RNNs Candidates with experience with Jupyter notebooks Candidates with experience utilizing virtual environments in Python Candidates with working experience with Git  Number of internships available: 2"
"Python Engineer, Natural Language Processing",Mumbai,Cactus Communications, 3.9,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
,Mumbai,Quantiphi Analytics,None,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
MACHINE LEARNING DATA ENGINEER,Kolkata,EdeXcare Learning Services,None,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Machine Learning Expert,Hyderabad,ZettaMine, 4.0,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Data Scientist,Pune,SG Analytics, 3.4,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Data Scientist,Bengaluru,C3.ai,None,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
"Data Scientist, Global Premium Services",Mumbai,Google,None,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Data Scientist,Chennai,DCKAP, 3.6,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Product ,Mumbai,TransUnion, 3.8,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Machine Learning,Hyderabad,Synxa IT Private Limited,None,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Machine Learning Developer,Kochi,SureEvents,None,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Sr. Software Engineer (Machine Learning),Pune,Talentica, 4.2,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Machine Learning- Computer Vision,Noida,Vidooly Media Tech, 4.5,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Research Scientist,Bengaluru,Amazon, 4.1,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Data Scientist,Bengaluru,Synechron, 3.6,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Data Scientists,Bengaluru,Tredence, 3.9,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Applied Scientist - Intern,Bengaluru,Amazon, 4.1,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Vice President - Machine Learning Platform Development Lead,Bengaluru,J.P. Morgan, 3.9,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Machine Learning Cloud Service Infrastructure Engineer,Bengaluru,Oracle, 3.5,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Data Scientist,Mumbai,BookMyShow,None,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Member Technical Staff - SDK,Bengaluru,Avi Networks, 4.7,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Senior Machine Learning Engineer,Hyderabad,WAVELABS TECHNOLOGIES, 4.3,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Machine Learning Staff Software Architect,Bengaluru,Marvell Technology, 3.7,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Data Scientist,Pune,Clairvoyant, 4.5,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Sr Engineer - Target India-2,Bengaluru,Target, 4.0,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
AWS Machine Learning-Consultant,Bengaluru,Wipro, 3.5,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Machine Learning (NLP),Gurgaon,FamePilot Internet Private Limited,None,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
Data Scientist,Mumbai,Ketto, 4.6,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
CIB Risk - Quantitative Research - ,Mumbai,J.P. Morgan, 3.9,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
DevOps Engineer for Machine Learning,Bengaluru,SAP, 4.4,"Want to work with India's no.1 mid-sized company? Lets talk!  Our Brand Editage (www.editage.com) a division of Cactus Communications provides high-quality services to academic, publishing, and pharmaceutical communities.  About our technology team We are a team of 110+ extremely agile and driven Techies. We are hosted completely on Amazon cloud and are proud of our ability to achieve 1-min deployments and to scale our hardware capacity up and down in minutes. The secret ingredient of our development recipe includes large portions of agile development with hints of extreme programming for Editage our Primary Line of Business. Laravel, PHP, query, Solr, PostgreSQL, Elasticsearch, nodejs, angular, mongodb, python, ansible, graylog, and new relic are few of the many technologies/services we employ. Unlike most techies, we are extremely social and believe that happiness levels are directly related to performance. We are very generous with our lunchboxes, quirky actions, smiles, and pranks - all of which help us maintain a charged up work environment. What's more - with the best work hours ethic in the industry and a company policy that takes fun very seriously, we make sure that we work hard and party harder!  PS: If you are a foodie, join us for the daily delicious breakfast.  We are looking for a Python Developer, NLP for our new Research and Development (R&D) cell that helps drive the business by creating products that are powered by NLP and AI  Your responsibilities You will be part of the team that creates NLP/data driven features for manuscript assessment, automated editing, machine translation and more Work with large data sets, extracting, structuring and storing data and working with various data stores like redshift, Athena, elasticsearch, neo4j etc Working hands-on with Python libraries- numpy, Spacy SCIPY, NLTK, NLP, core-nlp matplotlib, fastText, Gensim, word2vec, GloVe Design and implement algorithms to efficiently process, analyze, and serve massive datasets Serve as a key individual contributor within the R&D Team under Technology Department Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices Work on cypher and SQL queries for data fetch and retrieval Required Skills & Experience Self-motivated and creative- we are building from ground up, not tweaking legacy 2+ years working in Python In depth knowledge of backend infrastructure (e.g. Django, Flask, Falcon) Development & consumption of REST based APIs Designing applications for scale and resiliency Good communicator and team player Solid understanding of algorithms and data structures Familiarity with big data organization and big data tools: Spark, Hadoop, MongoDB, noSQL, redshift, AWS Athena Good understanding of chunking and POS tagging Preferred Skills & Experience Devops experience, working with setting up deep learning libraries, installing and working with python and similar libraries, AWS, Azure Machine learning, Sagemaker etc Experience with building models on deep learning frameworks (keras, tensorflow, cafe etc ) Experience with various ML models (Convolution Neural Network (CNN) Recurrent Neural Networks (RNN), AutoEncoder, Seq2Seq, Classifiers) Broad knowledge of machine learning (including topics such as graph theory, hierarchical modeling, and Bayesian inference)"
"Software engineer(Python), Machine learning platform",Bengaluru,"o9 Solutions, Inc.",None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Bengaluru,RxLogix,None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Hyderabad,InsideView,None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Product Owner- Machine Learning,Bengaluru,SAP, 4.4,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
,Bengaluru,AppDynamics, 4.4,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Bengaluru,Oracle, 3.5,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Senior Front End Engineer,Bengaluru,Domino Data Lab,None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Applied Scientist,Bengaluru,Amazon, 4.1,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Quality Engineer Associate-Machine Learning,Bengaluru,SAP, 4.4,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
,Chennai,Fintep Solutions,None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Staff Backend Engineer,Noida,Sumo Logic,None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Bengaluru,AIG, 3.1,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Devops Engineer with Security for Machine Learning Cloud Operations,Bengaluru,SAP, 4.4,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Chandigarh,Spice Digital, 4.1,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Bengaluru,Quanticate, 4.0,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Hyderabad,Sonetel,None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Bengaluru,J.P. Morgan, 3.9,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Principal Engineer,Bengaluru,AppDynamics, 4.4,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Chennai,Mindtree, 3.7,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Chennai,PickYourTrail, 4.6,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Technical Leader - ,Bengaluru,AppDynamics, 4.4,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Bengaluru,HP Inc., 4.1,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Pune,"Retail Solutions, Inc.",None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Gurgaon,Junglee Games, 4.1,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Lead AI Scientist,Bengaluru,Target, 4.0,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Sr. Manager DSA,Bengaluru,Target, 4.0,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Ahmedabad,iqm.com,None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Machine Learning Science Leader,India,CareerXperts,None,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Mumbai,Thoucentric, 4.7,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Mumbai,CreditMate, 4.3,"About o9: o9 is a fast-growing cloud-based premier AI platform for Planning and Operations. Gartner has positioned o9 in the visionaries quadrant of 2017 Magic Quadrant for S & OP Systems of Differentiation.  Description: Were looking for highly motivated individuals to join our Machine learning data platform team. You will be part of our platform engineering team and work closely with product, data infrastructure, services to build a scalable and highly resilient data platform. This individual should have the necessary background in algorithms and distributed systems to create systems for parallel and distributed processing of data.  Responsibilities: Productionize machine learning algorithms using Scikit, Numpy, Spark(PySpark), TensorFlow, etc. Create data pipelines using PySpark, Pandas to feed to machine learning algorithms. Improve the inference performance of the machine learning algorithms by running them in parallel and distributed manner. Profile and improve ML pipeline performance in general. Required skills: B.S. or M.S. degree in Computer Science, Machine Learning, or related technical field. Masters degree is preferred.2+ years of work or educational experience in Scalable system design and/or Machine learning using Python.Exceptional architecture abilities and experience with architectural patterns of large, highly-scalable, fault-tolerant and highly-available applications. Rigor in high code quality, automated testing, and other engineering best practices. Demonstrated familiarity with large datasets, and understanding of data analysis workflows is required. Experience in building industry grade data pipelines, preferably using frameworks like Spark or Pandas and working knowledge of applying machine learning and statistical models for real-world problems using machine learning packages like Keras, TensorFlow or other machine learning/statistical software is a huge plus."
Data Scientist,Bengaluru,Hitachi Vantara, 3.2,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,abc consultants, 4.2,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Internship (6months),Gurgaon,ToshBlocks, 4.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,Bloom Solutions,None,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Science- Intern,Gurgaon,Shipsy, 4.3,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Pune,e-Zest Solutions, 4.1,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,Pluto7, 4.8,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,DocsApp, 4.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,New Delhi,Telesoft Technologies,None,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Pune,Infiniopes, 3.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,Akamai, 4.1,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,Ericsson-Worldwide, 3.7,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Mumbai,Truebil, 4.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Pune,3SC Solutions,None,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Gurgaon,Profisor Services, 5.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Mumbai,GenieTalk, 4.5,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Gurgaon,dunnhumby, 3.5,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Software Engineer - India Location,Chennai,DrChrono,None,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Artificial intelligence,New Delhi,Eckovation Soutions, 2.9,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Internship Offer for AI based IOT Product,Ghaziabad,Liberin Technologies, 4.7,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Gurgaon,DEWI,None,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Applied Sciences Manager,Bengaluru,Amazon, 4.1,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,Alphonso, 5.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,JDA Software, 3.8,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,Almug Technologies, 5.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,Clustr, 4.6,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Maharashtra,Pivotchain Solutions, 5.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Bengaluru,Quantzig, 5.0,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Pune,Right Steps Consultancy,None,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
Data Scientist,Gurgaon,OLX,None,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers data to meaningful customer outcomes.  Responsibilities:  Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users Mentor and guide data science team members as well as developers and QA engineers working on the products Work with business managers to frame a problem, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Understand business data and how to use it appropriately in data analysis Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes Test performance of machine learning and deep learning models Qualifications: 10 to 15 years overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features 10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role Bachelor's degree in Computer Science, Operations Research or Math/Statistics Experience in working with multi-dimensional data Top notch communication skills to convey key insights from complex analysis, both oral and written Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData Experience with agile and Scrum Ability to work with distributed teams in a collaborative and productive manner Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities Desired Skills: Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis Exposure or experience in IoT/Industrial automation and/or DevOps experience"
,Bengaluru,AppDynamics, 4.4,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Software Engineering - Machine Learning Platform Web Specialist,Bengaluru,J.P. Morgan, 3.9,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Machine Learning-Consultant,Bengaluru,Wipro LTD, 3.5,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
,Ahmedabad,JB Solutions, 5.0,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Product Owner- Machine Learning,Bengaluru,SAP, 4.4,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Machine Learning  Engineer,Chennai,Rectras, 5.0,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Data Scientist,Bengaluru,Oracle, 3.5,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Senior Front End Engineer,Bengaluru,Domino Data Lab,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Data Analyst,Noida,Ericsson-Worldwide, 3.7,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Machine Learning QA Engineer,Pune,PubMatic,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Workfusion Machine Learning Engineer,Bengaluru,IntroPro,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
"Sr. Data Scientist - R, ",Pune,DataMetica, 3.9,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Applied Scientist,Bengaluru,Amazon, 4.1,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Lead Data Scientist / Machine Learning Expert,Bengaluru,Bidgely,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Machine Learning,Gurgaon,Zentrum Technologies Private Limited,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
V,Pune,LogicMonitor, 4.3,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Quality Engineer Associate-Machine Learning,Bengaluru,SAP, 4.4,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
,Chennai,Fintep Solutions,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Staff Backend Engineer,Noida,Sumo Logic,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Machine Learnin software engineer intern,Indore,Cognera,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Software Engineering - Machine Learning Platform Engineer Python,Bengaluru,J.P. Morgan, 3.9,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
"Data Research Associate - Machine Learning/Data Mining Techniques, Tamil Nadu - J-PAL South Asia",India,J-PAL,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Artificial Intelligence Developer,Noida,ArStudioz, 5.0,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Devops Engineer with Security for Machine Learning Cloud Operations,Bengaluru,SAP, 4.4,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Software Engineer,Pune,Xoriant, 3.5,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Software Engineer - Data Platform,Hyderabad,Apple, 4.6,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Data Scientist,Bengaluru,AIG, 3.1,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Data Science Intern,Mysore,iSOCRATES,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Research Analyst (Machine Learning),Bengaluru,ReConnect Energy,None,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Data Scientist,Chandigarh,Spice Digital, 4.1,"About the Role  Build and Release Engineering forms part of the Product Organization that has an exciting and challenging mission: Build, deploy, operate, scale and maintain platforms for all. While various Engineering groups focus on building specific products, Build and Release Engineering provides operational support for teams working to build, deploy, and support the entire AppDynamics suite of products.  We are a trusted partner to our customers based on a proven track record to bring improvements to our developers productivity.  As a Build and Release Operations Engineer reporting to the Global Development Center Build Manager, you will be responsible for supporting the services we provide to AppDynamics. The role will focus on key technologies including, but not limited to, AWS, TeamCity, Nexus, Artifactory, Sonar, Bitbucket, Git, Linux, Windows, Powershell, Ansible, Chef and Gradle. Your day to day activities will include responding to build failures, providing initial diagnosis of failure, connecting to the right teams, and following up to ensure issues are resolved. This position is empowered to enable short term fixes, as well as communicating with peers to plan and design long term solutions. Lastly, this position serves as a point of contact to other teams who consume our services.  Our ideal candidate is an individual whos driven by technology and enjoys automation and problem solving. We work hard, we like to challenge the status quo, and we enjoy having fun!  Areas of Responsibility:  Serve as part of a cross functional Agile team as the primary Build Systems support expert  Assist in development of custom dashboards and Business Transaction auditing for efficient monitoring of key business applications  Support and maintain Build and Release Engineering Public/Private cloud Infrastructure  Management and administration of AWS, TeamCity, and other automation infrastructure  Serve as an escalation point for production issues during shift or as required  Troubleshoot performance and stability issues using a wide variety of tools  Follow change management processes during implementations  Ensure that day-to-day operational requirements and SLAs are met  Work with key Business stakeholders to understand their business requirements, recommend potential solutions, and secure resources to deliver  Maintain key operational metrics and provide regular updates to upper management  Deliver operational services that focus on empowering our employees and reducing cost per end user  Seek opportunities to streamline standard operating procedures through automation  Job Requirements:  University degree (BS/MS) in Computer Science or equivalent experience  4 or more years of experience in a cloud focused environment  Proficiency in any of the scripting languages (shell,python,PHP,Perl,Ruby).  Candidates should demonstrate strong technical strengths in most of the following areas:  AWS major services - must have  Linux  Scripting  TeamCity  Nexus  Sonar  Artifactory  Docker  Git  Thorough understanding of networking concepts and Internet protocols  Experience with the following technologies is a plus:  Windows  Subversion  Atlassian About Us:  AppDynamics is an application performance monitoring solution that uses machine learning and artificial intelligence (AI) to provide real-time visibility and insight into IT environments. With our unique AIOps solution, you can take the right action at exactly the right time with automated anomaly detection, rapid root-cause analysis, and a unified view of your entire application ecosystem, including private and public clouds. Using AppDynamics, youll finally align IT, DevOps, and the business around the information that helps you protect your bottom line and deliver flawless customer experiences at scale.  AppDynamics is headquartered in San Francisco and has a R&D center in Bangalore.  Learn more about us here: https://www.appdynamics.com/  We're rated as the best workplace by most of our employees- https://www.glassdoor.co.in/Overview/Working-at-AppDynamics-EI_IE319551.11,22.htm  Here's why Cisco bought Appdynamics for whopping $3.7 Billion- https://economictimes.indiatimes.com/small-biz/startups/heres-why-cisco-paid-a-whopping-3-7-billion-to-appdynamics/articleshow/56804329.cms"
Data Engineer,Mumbai,Procter & Gamble, 4.0,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Business Data Analyst,Pune,Emerson, 3.6,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Machine Learning (NLP) Research Scientist,Bengaluru,Racetrack.ai, 4.2,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Senior Software Engineer (Machine Learning),India,Carta,None,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Bengaluru,Quanticate, 4.0,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
5524 Big Data/Machine Learning Test Engineer #137075,Pune,Credit Suisse, 3.6,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Director - Machine learning,Bengaluru,Zycus, 3.6,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Hyderabad,Sonetel,None,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Bengaluru,J.P. Morgan, 3.9,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Science Intern,Bengaluru,zeotap,None,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Chennai,Mindtree, 3.7,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Engineering,Bengaluru,Accenture, 3.9,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Principal Engineer,Bengaluru,AppDynamics, 4.4,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Technical Leader - ,Bengaluru,AppDynamics, 4.4,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Chennai,PickYourTrail, 4.6,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
,India,ICS Consultancy Services, 4.0,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Opportunity in Machine Learning,India,ICS Consultancy Services, 4.0,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Bengaluru,HP Inc., 4.1,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Pune,"Retail Solutions, Inc.",None,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Artificial Intelligence Engineer,Bengaluru,Spain base company,None,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Sr. Machine Learning Engineer,Bengaluru,Scientist Technologies, 5.0,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Software Engineering - Machine Learning Data Engineer,Bengaluru,J.P. Morgan, 3.9,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Quality Engineer - Machine Learning,Bengaluru,SuccessFactors,None,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
HIA/,Pune,Hella,None,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Software Engineer,Mumbai,J.P. Morgan, 3.9,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Member of Technical Staff - Machine Learning,Bengaluru,VMware, 4.3,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Gurgaon,United Airlines,None,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Lead AI Scientist,Bengaluru,Target, 4.0,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Data Scientist,Gurgaon,Junglee Games, 4.1,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Sr. Manager DSA,Bengaluru,Target, 4.0,"P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the worlds largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship.  The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.  Would you like to use your technical mastery to design and lead truly modern, scalable Big Data applications? Do you want to work in a team where your efforts will fuel P&G business?If so, this position is perfect for you. We are looking for Data Engineers to accelerate automation and increase effectiveness of our best-in-class Data Science group. You need to be ambitious and able to source and develop data models that will be used for advanced analytics. You will design and build scalable and automated solutions both in traditional cloud-based clusters and as serverless. Your partnership with data analysts is to understand use cases, data needs, and outcome objectives. You will work in partnerships and independently to re-engineer legacy technology or manual approaches to build new solutions. As a partner in our business, you will have project work and ad hoc requests that require agility and often dynamic response to business needs.  As a Data Engineer you will be: Working on advanced analytics use cases Executing data modeling and optimization of data and analytics solutions at scale Crafting and developing applications that source data from various systems utilizing advanced programming in Scala, Python, js, shell scripting and SQL Delivering analytical algorithms and applications (eg. machine learning) Engaging in proof of concepts and experiments together with data scientists and analysts to deliver new advanced analytics use cases Qualifications You should be a passionate leader and technologist who has graduated with a BS or MS in Business/Management Information Systems and/or Computer Science/Engineering, Programming/Software Development or Operations Research or Statistics or with proven track of record from programming areas. You need to have demonstrated deep understanding in applied Big Data technologies : Scripting languages for manipulating data (eg. Scala, Python) Big Data (Hive, Impala) and NoSQL databases SQL, Linux Shell Scripting Cloud services frameworks Data Mining, Data Modeling, and Data Provisioning (acquisition from various sources, transformation and sharing) Dedication from us:  You'll be at the core of breakthrough innovations, be given exciting assignments, lead initiatives, and take ownership and responsibility, in creative work spaces where new ideas flourish. All the while, you'll receive world-class training to help you become a leader in your field. It is not just about what you'll do, but how you'll feel: welcomed, valued, purposeful, challenged, heard, and inspired.  What we offer: Continuous mentorship you will collaborate with passionate peers and receive both formal training as well as day-to-day mentoring from your manager Dynamicandsupportiveworkenvironment employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance. Just So You Know:  We are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: Everyone valued. Everyone included. Everyone performing at their peak."
Intern,Bengaluru,Nabler, 4.1,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Mumbai,Thoucentric, 4.7,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Ahmedabad,iqm.com,None,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Mumbai,CreditMate, 4.3,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Machine Learning Science Leader,India,CareerXperts,None,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Bengaluru,Hitachi Vantara, 3.2,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Bengaluru,Noodle.ai,None,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Bengaluru,abc consultants, 4.2,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Bengaluru,Gray Matter,None,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Bengaluru,Bloom Solutions,None,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Internship (6months),Gurgaon,ToshBlocks, 4.0,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
vacancies in Machine Learning,India,ICS Consultancy Services, 4.0,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Science- Intern,Gurgaon,Shipsy, 4.3,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Job Opening for ,Mumbai,ICS Consultancy Services, 4.0,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Chatbot,Noida,BirlaSoft, 3.2,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Pune,e-Zest Solutions, 4.1,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Lead Data Scientist,Mumbai,Boston Consulting Group, 3.8,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
,Mumbai,Raw Algo,None,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
ParallelDots - Content Writer - Machine Learning (0-1 yrs) ,Gurgaon,ParallelDots, 4.6,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Python Development,Ahmedabad,Finbyz Tech Private Limited, 5.0,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Bengaluru,Pluto7, 4.8,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Bengaluru,DocsApp, 4.0,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,New Delhi,Telesoft Technologies,None,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Science Specialist,Bengaluru,Clustr, 4.6,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Bengaluru,Akamai, 4.1,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Machine Learning/NLP Lead,Bengaluru,Digital Aristotle,None,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Software Engineer,Bengaluru,Cisco Systems, 4.1,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,India,Iris Software, 3.7,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Asp.,New Delhi,Diverse Lynx India, 4.2,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Pune,Infiniopes, 3.0,"Nabler is a pure-play digital analytics company with offices in North Carolina, US and Bangalore. We enable marketers take advanced data-driven decisions and boost the effectiveness and success across digital ecosystem. We have a team composed of passionate professionals who come from diverse backgrounds offering solutions across business and are grouped under core services mentioned in the website www.nabler.com.  Nabler has been rated one of the Great places to work in 2019, is now looking for Interns.  If you are an active learner and curious to experiment with unconventional approaches to solve business problems using data, we would like to talk to you.  Required to extract and process data using Python for Machine Learning projects.  Requirements  Excellent knowledge of Python is mandatory. Knowledge of any NoSQL database will be an added advantage, but not mandatory. Knowledge of Flask / Django framework will be a plus.  Duration: 2 months  ]]>"
Data Scientist,Gurgaon,Think Future Technologies, 3.7,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Mumbai,Truebil, 4.0,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Senior Engineer - Machine Learning AI,Bengaluru,Han Digital Solution,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Bengaluru,Ericsson-Worldwide, 3.7,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Science Internship,Mumbai,Catallyst Executive Education Institute,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Fresher - Analytics,Kolkata,Sibia Analytics, 3.4,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Senior Quality Specialist - Machine learning,Bengaluru,SAP, 4.4,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Pune,3SC Solutions,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Bengaluru,Bidgely,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Software Engineer,Bengaluru,Motorola Solutions, 3.7,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Software Engineer,Gurgaon,Orange, 3.8,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Engineering Intern,Kochi,FullContact,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Gurgaon,Profisor Services, 5.0,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Gurgaon,dunnhumby, 3.5,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Engineer II,Ahmedabad,S&P Global,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Bengaluru,Zinier,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Mumbai,GenieTalk, 4.5,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Specialist- Machine Learning Algorithms (5+ Years) For am Emerging Product ,Bengaluru,Zyoin, 3.6,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
AI Specialist,Kochi,Icubespro,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
"SDE - Machine Learning, Traffic Quality",Bengaluru,ADCI - Karnataka,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Artificial intelligence,New Delhi,Eckovation Soutions, 2.9,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Software Engineer - India Location,Chennai,DrChrono,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Mumbai,InCred, 4.0,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Internship Offer for AI based IOT Product,Ghaziabad,Liberin Technologies, 4.7,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Gurgaon,DEWI,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Applied Sciences Manager,Bengaluru,Amazon, 4.1,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
DATA SCIENTIST,Mumbai,Weatherford,None,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,New Delhi,cube26, 3.6,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Pune,SkillVentory, 4.2,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Bengaluru,Alphonso, 5.0,"Exp: 1-4 Years Location: Gurgaon Skill-sets:Machine Learning algorithms, case framing, data collection, data exploration, model building, deployment, Tableau, R, SQL  Job Description: Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Extending companyu2019s data with third party sources of information when needed Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner Creating automated anomaly detection systems and constant tracking of its performance"
Data Scientist,Bengaluru,TheMathCompany, 4.4,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Software Development Engineer II,Hyderabad,Amazon, 4.1,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,JDA Software, 3.8,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Gurgaon,Analytics Vidhya, 3.8,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Thiruvananthapuram,Nissan,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,Almug Technologies, 5.0,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Maharashtra,Pivotchain Solutions, 5.0,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,New Delhi,Ank Aha, 4.7,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,ZestMoney, 4.5,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,Clustr, 4.6,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,Quantzig, 5.0,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Team Lead - Machine Learning,New Delhi,Airwoot,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Pune,Right Steps Consultancy,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Technical Manager - Machine Learning,Kochi,SureEvents,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Gurgaon,OLX,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Mumbai,Star India, 3.9,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Lead Data Engineer,Hyderabad,SpringML,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Senior Data Engineer,Pune,Ridecell,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,New Delhi,GoPaisa, 3.1,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,Data Semantics,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Mumbai,Flexiloans, 3.5,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Software Development Engineer,Chennai,Amazon, 4.1,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Gurgaon,LexInnova Technologies,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,Pattem Digital, 4.8,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,Informatica, 4.0,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Senior Data Scientist,Bengaluru,Amazon, 4.1,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Pune City,Ecolibrium Energy, 4.3,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Startup Solution Architect - ML/AI,Bengaluru,Amazon, 4.1,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Gurgaon,United Airlines Inc.,None,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Bengaluru,Magicbricks, 4.0,"We are looking out for people who share our passion for Analytics and energy to build a great company. We have outlined few criteria that would make you successful in this role.  Responsibilities: Solving complicated business problems for organizations, leveraging conventional & new age data sources and a wide array of techniques. Liaising with the clients and stakeholders to understand their requirements, challenges etc. and keeping them up to date on the progress of our proposed solution. Staying connected to the Analytics industry trends- data, techniques, technology etc. and leveraging them to develop learning packages. Contributing to the hiring and learning programs- through interviews, sessions, content creations etc. based on the nature of the engagements.  Requirements: Experience of working on analytics projects and initiatives, preferably around 2-5 years. Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series etc). Passion to learn new technologies, techniques to stay ahead of the Analytics industry curve."
Data Scientist,Chennai,Tata Consultancy Services,None,"Job Description  Should have Knowledge on Machine Learning frameworks - Keras, Tensor Flow , H2.ai Good experience in Python & Big data technologies  Hadoop, Hive, Hbase, Pig, Spark, Py-Spark Should have experience in using statistical languages and packages to manipulate data, build models, and draw insights Should have experience in Machine Learning techniques and concepts (Clustering, Regression, Decision Trees, NLP, Neural Networks, etc.)  Job Function  TECHNOLOGY  Role  Analyst  Job Id  145408  Desired Skills  Data Science  Desired Candidate Profile  Qualifications : BACHELOR OF ENGINEERING, BACHELOR OF SCIENCE (B.Sc), MAST. OF SC. (ENGG.), MASTER OF STATISTICS, Ph.D"
Data Scientist,Bengaluru,IQLECT, 3.9,"Job Description  Should have Knowledge on Machine Learning frameworks - Keras, Tensor Flow , H2.ai Good experience in Python & Big data technologies  Hadoop, Hive, Hbase, Pig, Spark, Py-Spark Should have experience in using statistical languages and packages to manipulate data, build models, and draw insights Should have experience in Machine Learning techniques and concepts (Clustering, Regression, Decision Trees, NLP, Neural Networks, etc.)  Job Function  TECHNOLOGY  Role  Analyst  Job Id  145408  Desired Skills  Data Science  Desired Candidate Profile  Qualifications : BACHELOR OF ENGINEERING, BACHELOR OF SCIENCE (B.Sc), MAST. OF SC. (ENGG.), MASTER OF STATISTICS, Ph.D"
Data Scientist,Maharashtra,Angel broking, 2.9,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Bengaluru,Entropik Technologies, 3.9,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Machine Learning Developer / Data Scientist,India,Aizant Global Analytics,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Noida,Algoscale, 3.9,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
"Software Engineer, Ad Optimization & Infrastructure",Multi,Etsy,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
DATA SCIENTIST,Gurgaon,Incedo, 3.0,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Software Senior Engineer,Bengaluru,Dell, 3.9,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Bengaluru,Myntra / Jabong,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Science/ ,Pune,Merkle Sokrati,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Bengaluru,cross-tab marketing services pvt., 3.4,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Machine/Deep Learning with SPARK/2-4Yrs/BLR,Hyderabad,PROLIM,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Chennai,Ness Digital Engineering,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Bengaluru,Zauba Corp, 3.8,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Machine/Deep Learning with SPARK/2-4Yrs/,Bengaluru,PROLIM Corporation, 2.9,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Computer Vision Internship,Noida,Aspagteq Private Limited Noida,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Pune,Aera Technology,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
,Mumbai,Zyoin, 3.6,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Thiruvananthapuram,Flytxt,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Noida,Valiance Solutions,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Bengaluru,Vedantu,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Bengaluru,Youplus,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Kochi,Calpine Group,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Internship (6months),Gurgaon,Tosh Innovations,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Noida,Crisp Analytics, 4.6,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,India,Agnik, 4.9,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Gurgaon,Talent Integrators, 5.0,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Pune,Wolters Kluwer,None,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Hyderabad,MTW LABS, 4.5,"Requirements Should have good knowledge of statistics and machine learning techniques Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value Should have good problem solving skills Should have working knowledge or experience with tools such as R, Matlab etc Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner  Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques. Data mining using state-of-the-art methods. Extending companys data with third party sources of information when needed. Enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Doing ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and constant tracking of its performance  Skills and Qualifications Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc... Experience with common data science toolkits, such as R, Matlab, Python related etc. Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard Proficiency in using query languages such as R, SQL etc. Experience in Python is plus Experience with various sdks like mitie, dib, stanford NLP, etc are preferred Good applied statistics skills, such as distributions, statistical testing, regression, etc. Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise Were looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field"
Data Scientist,Bengaluru,Yottaasys, 5.0,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Cumulations Technologies, 4.8,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,ShareChat, 5.0,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Principal Engineer (Machine Learning & Deep learning),Bengaluru,Han Digital Solution,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Gurgaon,Kvantum, 4.3,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Lead Data Scientist,Bengaluru,Tavant technologies ltd, 3.6,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,New Delhi,Sentieo,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,India,Leoforce,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Altair Engineering,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Hyderabad,SoulPage IT Solutions, 4.5,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Tech Mahindra, 3.9,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Eka Software, 3.6,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Chennai,Crayon Data, 4.0,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Pune,Nihilent,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Lead Data Scientist,Pune,Qualys, 2.3,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Noida,Gauge Data Solutions, 3.1,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Senior Data Analyst - Ad Tech,Gurgaon,Saavn, 4.4,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Chennai,Magna Infotech, 2.9,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Pune,Nitor Infotech, 2.4,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,India,DBS Bank,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Xebia, 4.1,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Travash Software Solutions, 4.0,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Softtek,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Gurgaon,Mobileum, 3.5,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Tamil Nadu,f5, 5.0,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Chennai,Saaki Argus And Averil Consulting, 4.3,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Saksoft, 3.7,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Chennai,Han Digital Solution,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Software Developer 2,Noida,Oracle, 3.5,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
QA Automation Engineer - E2E workflow QA team,India,EFI,None,"We are Yottaasys India's fastest growing and award winning AI startup (recently we won the Best AI innovator award from honorable IT minister and were also the Nasscom Top 50 emerging startup in 2017). we are in the growth stage and rapidly but selectively expanding our team of rock star data scientists. Currently we are looking for 1-3 years experienced Python based data scientist with deep coding skills and understanding of: Scikit-learn, pandas and other python data sciences libraries deep coding skills in python for data scrapping and munging detailed understanding of basic algorithms (Dtrees, Bayesian, Knn etc) and working level understanding of advanced algorithms XGB, Catboost, lightGBM etc good understanding of fundamentals of statistics and math behind the machine learning algorithms good understanding of python cross validation, grid search, stacking etc working level understanding of big data ecosystem HDFS ecosystem If you are a kaggle ranker that will be a bonus.  Best in class environment, salary and early bird Esops are on the offer, buzz us if you think you are that geek data scientist we are looking for....."
Data Scientist,Bengaluru,Anlage HRO Services, 3.9,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Senior Engineer,Bengaluru,Target, 4.0,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Hyderabad,Hiddime, 4.6,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Natural Language Processing (NLP),Bengaluru,Accenture, 3.9,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Chennai,BrandIdea Consultancy P Ltd, 2.5,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,Conttext,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,Atonarp,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Mumbai,Corporate Zoom,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Mumbai,Bigiota,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,Germane Analytics Pvt Ltd,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,New Delhi,Fitfyles,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,ScaleIn,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Chandigarh,Firminiq,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Gurgaon,itForte,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
"ES Tech, Applied Scientist",Bengaluru,Amazon, 4.1,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Science Expert,Bengaluru,Hewlett Packard Enterprise, 4.1,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Gurgaon,Gartner,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,HolidayMe,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,Educational Initiatives,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Machine Learning/Deep Learning/2-5 Yrs/BLR,Hyderabad,PROLIM,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,ExpertEase,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Chennai,Applied Data Finance,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
DATA SCIENTIST,Bengaluru,The Data Team, 4.0,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Noida,Exzeo, 4.1,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,HP, 4.1,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,Walmart Labs, 3.3,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Mumbai,WNS Global Services,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Science Professionals,Kolkata,Rebaca, 3.1,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Backend Engineer,Noida,Sumo Logic,None,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,ITC Infotech India Ltd, 3.2,"Roles and responsibilities  Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight: Translate business objectives into analytic approaches, and identify data sources to support analysis. Analyze and model structured data using advanced statistical methods Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications. Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods. Implement algorithms and software needed to perform analyses Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management. Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data Communicate results and educate others through reports and presentations. Essential skills required Education / professional qualifications  Masters, or PhD in Computer Science, Statistics, Mathematics  Prior Experience:  Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience  Technical skills Ability to break down complex problems, and develop strategies to solve them Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint. Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred Experience with command-line scripting, data structures and algorithms Ability to work in a Linux environment, and process large amounts of data in a cloud environment Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby) Behavioral / team skills Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills Excellent written and verbal communication skills Team player; self-driven and ability to work independently Team player; self-driven and ability to work independently"
Data Scientist,Bengaluru,Chase,None,"JPMorgan Chase is a leading global financial services firm with assets of over $1.1 trillion and operations in more than 50 countries. The firm is a leader in Investment Banking, Financial Services for consumers and businesses, financial transaction processing, asset and wealth management, and private equity. Under the JPMorgan and Chase brands, the firm serves millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients. Further information about J.P. Morgan is available at http://www.jpmorgan.com/.  The role is for a Machine Learning Engineer  Lead within the Corporate Machine Learning Engineering and Services function for corporate functions across JPMorgan Chase, including Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal, and all functions within the Corporate Administrative Office (CAO). The ML Engineering and Services team will create services and platforms that will provide re-usable components and an end-to-end development to deployment environment to accelerate time-to-market for data science teams.  The ML Engineer - Lead in Bangalore will be part of a globally distributed team, with data science and engineering partners in New York and EMEA. He/she will lead a team of engineers to productionize robust and scalable ML models, and enable the services to be deployed and integrated into existing business workflow. He/she will also build common ML capabilities used across Corporate based on those models. These capabilities will be delivered in an agile way, on internal open source code base, in a test driven manner. This is an exciting opportunity to work on cutting-edge solutions and have a profound influence on the business processes of a leading global bank.  Responsibilities Build common ML capabilities used across Corporate based on machine learning models Lead development of one or more of: Next-generation big data based machine learning frameworks and back-end services Front-end web applications and back-end services that integrate with other products. High-performance processing and analytics applications using Spark Robust analytic data pipelines Automate and streamline existing processes, procedures, and toolsets Innovate new ways of managing, transforming and validating data Ensure code paths are unit tested, defect free and integration tested Mentor and coach junior team members to build a high-performing team  Qualifications/ Technical skills BA/BS degree or equivalent experience in Computer Science, Information Technology or related disciplines 10 years of exceptional hands-on knowledge of robust software design and development Strong Java/ Python programming skills and Web Services (spring boot) Experience in Big Data technologies and utilities (Hadoop, Spark SQL, Hive, Impala, Pig, Kafka) Expertise in distributed computing and micro services Exposure to or interest in ML Expertise in designing and implementing scalable solutions in the analytics space Experience in building reliable and auditable CICD deployment pipeline using Jenkins Exposure working with Cloud based applications Proven proficiency with data and variety of databases Exposure/competence with Agile Development approach Ability to collaborate with high-performing teams and individuals throughout the firm to accomplish common goals Financial Services background or experience preferred."
Data Scientist,Bengaluru,Worksys,None,"JPMorgan Chase is a leading global financial services firm with assets of over $1.1 trillion and operations in more than 50 countries. The firm is a leader in Investment Banking, Financial Services for consumers and businesses, financial transaction processing, asset and wealth management, and private equity. Under the JPMorgan and Chase brands, the firm serves millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients. Further information about J.P. Morgan is available at http://www.jpmorgan.com/.  The role is for a Machine Learning Engineer  Lead within the Corporate Machine Learning Engineering and Services function for corporate functions across JPMorgan Chase, including Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal, and all functions within the Corporate Administrative Office (CAO). The ML Engineering and Services team will create services and platforms that will provide re-usable components and an end-to-end development to deployment environment to accelerate time-to-market for data science teams.  The ML Engineer - Lead in Bangalore will be part of a globally distributed team, with data science and engineering partners in New York and EMEA. He/she will lead a team of engineers to productionize robust and scalable ML models, and enable the services to be deployed and integrated into existing business workflow. He/she will also build common ML capabilities used across Corporate based on those models. These capabilities will be delivered in an agile way, on internal open source code base, in a test driven manner. This is an exciting opportunity to work on cutting-edge solutions and have a profound influence on the business processes of a leading global bank.  Responsibilities Build common ML capabilities used across Corporate based on machine learning models Lead development of one or more of: Next-generation big data based machine learning frameworks and back-end services Front-end web applications and back-end services that integrate with other products. High-performance processing and analytics applications using Spark Robust analytic data pipelines Automate and streamline existing processes, procedures, and toolsets Innovate new ways of managing, transforming and validating data Ensure code paths are unit tested, defect free and integration tested Mentor and coach junior team members to build a high-performing team  Qualifications/ Technical skills BA/BS degree or equivalent experience in Computer Science, Information Technology or related disciplines 10 years of exceptional hands-on knowledge of robust software design and development Strong Java/ Python programming skills and Web Services (spring boot) Experience in Big Data technologies and utilities (Hadoop, Spark SQL, Hive, Impala, Pig, Kafka) Expertise in distributed computing and micro services Exposure to or interest in ML Expertise in designing and implementing scalable solutions in the analytics space Experience in building reliable and auditable CICD deployment pipeline using Jenkins Exposure working with Cloud based applications Proven proficiency with data and variety of databases Exposure/competence with Agile Development approach Ability to collaborate with high-performing teams and individuals throughout the firm to accomplish common goals Financial Services background or experience preferred."
Data Scientist,Hyderabad,[x]cube LABS,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Artificial Intelligence (AI) Engineer,Bengaluru,Han Digital Solution,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Hyderabad,Micron,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Software Development Engineer II,Gurgaon,Expedia Group, 3.8,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Bengaluru,Altair, 4.5,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Hyderabad,Micron, 3.1,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Sr Data Scientist,Hyderabad,Amazon, 4.1,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,New Delhi,Pinnacle Digital Analytics, 2.5,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Applied Scientist I,Bengaluru,Amazon, 4.1,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Advanced Development Expert/Technologist,Bengaluru,Hewlett Packard Enterprise, 4.1,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
AI ,Mumbai,Amazon, 4.1,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Bengaluru,Conduent, 2.6,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Bengaluru,Diamondpick, 3.7,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Bengaluru,EdgeVerve Systems, 3.5,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Karnataka,Merak,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Noida,Healtheoz India,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
"Senior Quality Engineer/ SDET, ",Bengaluru,Lookout,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Gurgaon,Limetray, 3.6,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Software Architect (,Pune,LogicMonitor, 4.3,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Applied Scientist II,Bengaluru,Amazon, 4.1,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Bengaluru,BDB,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Bengaluru,SureEvents,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Chandigarh,DataToBiz2,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Bengaluru,AISPL - Karnataka,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Mumbai,Hookfish,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Gurgaon,Number Theory,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Noida,Beatmy Salary,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Data Scientist,Bengaluru,WeRecruit Talent,None,"Job Description: BTech or MTech in Computer Science, Statistics or related field, with a specialization in Data Science / Machine Learning. Strong theoretical foundation in mathematical statistics Hands-on experience with a wide variety of predictive modeling, machine learning, data mining, statistical, text mining, and optimization algorithms. Deep data analysis and data validation ability to prepare structured and unstructured data for machine learning algorithms. Experience developing static and interactive data visualizations is a plus. Experience using statistical tools such as R, Weka, etc. is a plus. Familiarity with relational databases and SQL, knowledge of NoSQL and MongoDB or CouchDB is a plus. Experience working with large data sets, experience working with distributed computing tools such as Hadoop, MapReduce, Mahout, Spark, Hive, Pig, etc. is a plus.  Experience Range: 2 - 8 years  Educational Qualifications: Any graduation,  Job Responsibilities: ""Building highly scalable server-side solutions which include Web APIs for mobile apps and always alive processing engines that handle incoming stream of requests and act on them for a variety of activities that include generating analytics, reports, data management operations, etc. Data Scientist or Data Mining expert who will work in an Agile environment and implement end-to-end Analytical solutions. Design, evaluate and implement highly scalable algorithms for processing large amounts of data parallely. Partner with Engineering teams to solve customer problems and identify trends and opportunities.""  Skills Required : Predictive Modeling, Machine Learning, Data Mining, R, Weka, NoSQL, MongoDB, CouchDB, Hadoop, MapReduce,"
Machine/Deep Learning with SPARK/2-4Yrs/BLR,Hyderabad,PROLIM,None,"Description:  Machine learning/ Deep learning with Spark experience( Mandate).  Job Responsibilities: Development of machine learning and deep learning using spark library  * Tuning of the parameters in HDP for spark jobs  * Monitoring of jobs in spark  * Development of algorithms for streaming data  *A team player, eager to invest in personal and team growth Experience:  A minimum of 2 years of relevant experience in a similar role  Qualification:  Bachelor of Engineering (BTECH / BE) or Masters (MTECH / MS / MCA ) in Computer Science / Electronics / Information Science  Skills Required: Mandatory Good knowledge on machine learning and deep learning  * Good knowledge on handling image and streaming data  * Usage of spark libraries for machine and deep learning  * Good experience in Python coding  * Strong unit test and debugging skills  * Adaptability to changing environment * Optional  Knowledge on Scala programming  Knowledge on SQL and NOSQL database  Knowledge on working in Hadoop environment  Kindly share the Profile with 2 to 4 yrs of experience.. Shortlisted candidates will have initial telecom interview and who ever clear telecom will be called for the Interview.  Note : This is different JD for other ML Requirement.. SO Kindly Mention ML/Dl with Spark in Subject line while sharing the Profiles.. About PROLIM Corporation    PROLIM is a leading provider of end-to-end IT, PLM and Engineering Services and Solutions for Global 1000 companies. They understand business as much as technology, and help their customers improve their profitability and efficiency by providing high-value technology consulting, staffing, and project management outsourcing services.  Their IT and PLM consulting offerings include; Advisory, PLM Software/Services, Program Management, Solution Architecture Training/Staffing, Cloud Solutions, Servers/Networking, Infrastructure, ERP Practices and QA Services. Engineering services include Data Translation, CAD/CAM/CAE, Process & Product Engineering, Prototyping, and Testing/Validation within a wide range of markets and industries."
Data Scientist,Chennai,Ness Digital Engineering,None,"Description:  Machine learning/ Deep learning with Spark experience( Mandate).  Job Responsibilities: Development of machine learning and deep learning using spark library  * Tuning of the parameters in HDP for spark jobs  * Monitoring of jobs in spark  * Development of algorithms for streaming data  *A team player, eager to invest in personal and team growth Experience:  A minimum of 2 years of relevant experience in a similar role  Qualification:  Bachelor of Engineering (BTECH / BE) or Masters (MTECH / MS / MCA ) in Computer Science / Electronics / Information Science  Skills Required: Mandatory Good knowledge on machine learning and deep learning  * Good knowledge on handling image and streaming data  * Usage of spark libraries for machine and deep learning  * Good experience in Python coding  * Strong unit test and debugging skills  * Adaptability to changing environment * Optional  Knowledge on Scala programming  Knowledge on SQL and NOSQL database  Knowledge on working in Hadoop environment  Kindly share the Profile with 2 to 4 yrs of experience.. Shortlisted candidates will have initial telecom interview and who ever clear telecom will be called for the Interview.  Note : This is different JD for other ML Requirement.. SO Kindly Mention ML/Dl with Spark in Subject line while sharing the Profiles.. About PROLIM Corporation    PROLIM is a leading provider of end-to-end IT, PLM and Engineering Services and Solutions for Global 1000 companies. They understand business as much as technology, and help their customers improve their profitability and efficiency by providing high-value technology consulting, staffing, and project management outsourcing services.  Their IT and PLM consulting offerings include; Advisory, PLM Software/Services, Program Management, Solution Architecture Training/Staffing, Cloud Solutions, Servers/Networking, Infrastructure, ERP Practices and QA Services. Engineering services include Data Translation, CAD/CAM/CAE, Process & Product Engineering, Prototyping, and Testing/Validation within a wide range of markets and industries."
Data Scientist,Bengaluru,cross-tab marketing services pvt., 3.4,"Requirements: Statistics/Statistical programming(candidates have choice of using either R or Python). SQL/Hive script writing. Machine Learning models. 6+ years of industry work experience in data scientist projects. Hadoop Exp is msut. Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management system.  Responsibilities: Build and evaluate predictive and decision models to be deployed in production systems, or for research. Analysis of large amounts of historical data, determining suitability for modeling, data clean-up and filtering, pattern identification and variable creation, selection of sampling criteria, generating performance definitions and variables. Conducting experiments with different types of algorithms and models, analyzing performance, to identify the best algorithms to employ. Architect and develop operational models that run at scale thru partnership with data engineer teams."
Data Scientist,Bengaluru,Zauba Corp, 3.8,"Requirements: Statistics/Statistical programming(candidates have choice of using either R or Python). SQL/Hive script writing. Machine Learning models. 6+ years of industry work experience in data scientist projects. Hadoop Exp is msut. Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management system.  Responsibilities: Build and evaluate predictive and decision models to be deployed in production systems, or for research. Analysis of large amounts of historical data, determining suitability for modeling, data clean-up and filtering, pattern identification and variable creation, selection of sampling criteria, generating performance definitions and variables. Conducting experiments with different types of algorithms and models, analyzing performance, to identify the best algorithms to employ. Architect and develop operational models that run at scale thru partnership with data engineer teams."
Machine/Deep Learning with SPARK/2-4Yrs/,Bengaluru,PROLIM Corporation, 2.9,"Requirements: Statistics/Statistical programming(candidates have choice of using either R or Python). SQL/Hive script writing. Machine Learning models. 6+ years of industry work experience in data scientist projects. Hadoop Exp is msut. Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management system.  Responsibilities: Build and evaluate predictive and decision models to be deployed in production systems, or for research. Analysis of large amounts of historical data, determining suitability for modeling, data clean-up and filtering, pattern identification and variable creation, selection of sampling criteria, generating performance definitions and variables. Conducting experiments with different types of algorithms and models, analyzing performance, to identify the best algorithms to employ. Architect and develop operational models that run at scale thru partnership with data engineer teams."
,Mumbai,Zyoin, 3.6,"Roles & Responsibilities:-   Design scalable predictive models with large number of features  Be responsible for the entire machine learning implementation process: model design, feature planning, system infrastructure, production setup and monitoring, and release management  Use machine learning techniques optimized for distributed computing environments  Skills & experience includes:  Prefer Ph.D. (will consider B.S. or M.S. in Computer Science or related field)  Advanced knowledge of predictive analytics / statistical modeling / machine learning such as regression analysis, predictive models, Bayesian classification, collaborative filtering, decision trees, and clustering problems applied to large data sets  Expert in at least one of: Ruby, Python,R, Java, C++  Good understanding of web technologies and Unix / Linux  Full-time commitment  Experience with NoSQL / graph databases: Neo4J, MongoDB, Riak, Cassandra  Experience with cloud technologies: AWS, Rackspace."
Computer Vision Internship,Noida,Aspagteq Private Limited Noida,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Project Intern - Delhi Metro Automatic Delay Prediction System,Noida,Hackveda, 1.0,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Pune,Aera Technology,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Thiruvananthapuram,Flytxt,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Noida,Valiance Solutions,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Bengaluru,Vedantu,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Bengaluru,Youplus,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Python Developer,Noida,Spaak, 4.1,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Kochi,Calpine Group,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Noida,Crisp Analytics, 4.6,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Internship (6months),Gurgaon,Tosh Innovations,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Pune,Wolters Kluwer,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,India,Agnik, 4.9,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Gurgaon,Talent Integrators, 5.0,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Hyderabad,MTW LABS, 4.5,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Bengaluru,Yottaasys, 5.0,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Bengaluru,ShareChat, 5.0,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Principal Engineer (Machine Learning & Deep learning),Bengaluru,Han Digital Solution,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Bengaluru,Cumulations Technologies, 4.8,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,Gurgaon,Kvantum, 4.3,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Lendingkart - Telesales Role - Loan Vertical (0-3 yrs) ,Ahmedabad,Lendingkart, 3.9,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Lead Data Scientist,Bengaluru,Tavant technologies ltd, 3.6,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Software Development Engineer II,Bengaluru,Microsoft, 4.1,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Software Engineering - Machine Learning Platform Engineer Python,Bengaluru,Chase,None,"About the company: Aspagteq is a high-end, leading software development company based in Singapore, providing expert IT solutions to its global clients, focusing on enterprise solutions, iOS & Android mobile app development, web solutions & embedded system design established in December 2014.  About the internship/job: Selected intern's day-to-day responsibilities include: 1. Designing computer vision algorithms and implementing them in robust, efficient, and well-tested code 2. Developing innovative solutions for various problems related to segmentation, object detection, feature analysis and classification for applications in the semi-conductor industry 3. Researching & implementing high-end efficient models in machine learning (e.g. deep learning) for accurate analysis and classification of large images  Who can apply: Only those students or freshers can apply who: are available for full time (in-office) internship have relevant skills and interests can start the internship between 9th Jul'19 and 8th Aug'19 are available for duration of 1 month have already graduated or are currently in any year of study are from Noida and neighboring cities Females willing to start/restart their career may also apply Number of internships/jobs available: 2  Categories: Computer Vision,Computer Science,Engineering"
Data Scientist,New Delhi,Sentieo,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Research Scientist II,Chennai,Amazon, 4.1,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Bengaluru,Altair Engineering,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,India,Leoforce,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Hyderabad,SoulPage IT Solutions, 4.5,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
,Mumbai,Han Digital Solution (P) Ltd.,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Software Engineer - JavaScript,Bengaluru,Instart Logic,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Bengaluru,Tech Mahindra, 3.9,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Research Data Scientist,Bengaluru,Analytics Quotient, 3.4,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Bengaluru,Eka Software, 3.6,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Product Owner- Machine Learning,Bengaluru,SuccessFactors,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Pune,Nihilent,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Chennai,Crayon Data, 4.0,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Product Designer (,Bengaluru,ThoughtSpot,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Lead Data Scientist,Pune,Qualys, 2.3,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Noida,Gauge Data Solutions, 3.1,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Senior Data Analyst - Ad Tech,Gurgaon,Saavn, 4.4,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Senior Developer,Bengaluru,J.P. Morgan, 3.9,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Chennai,Magna Infotech, 2.9,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Bengaluru,Xebia, 4.1,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Pune,Nitor Infotech, 2.4,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,India,DBS Bank,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Bengaluru,Softtek,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Gurgaon,Mobileum, 3.5,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Bengaluru,Travash Software Solutions, 4.0,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Bengaluru,Saksoft, 3.7,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Tamil Nadu,f5, 5.0,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Data Scientist,Chennai,Saaki Argus And Averil Consulting, 4.3,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
Devops Engineer with Security for Machine Learning Cloud Operations,Bengaluru,SuccessFactors,None,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
"Program Manager, Search and Sensei",Noida,Adobe, 4.2,"We're looking for highly qualified Data Scientists to join our team and help us build an ever-more excellent service for our customers. We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small (but growing team) where you will have a major voice in deciding which projects to undertake. We're looking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.  Responsibilities: Selecting and engineering features to build and based on mining of our large text and financials database. Prototyping/Testing algorithms to help inform us what to build. Training and tuning a variety of machine learning models. Data mining using NLP & state-of-the-art methods. Enhancing data collection procedures to include information that is relevant for building analytic systems.  Requirements: Knowledge and hands-on working experience with ML techniques and tools. Strong understanding of basic statistics concepts including population, confidence intervals, correlation, significance, probability, distributions, hypothesis testing, etc. Strong grounded concepts and application knowledge of ML techniques including linear/logistic regression, decision trees, classification, clustering, ensembles, text mining to build models. Hands-on experience with Python and familiarity with machine learning frameworks. Comfortable with data visualization tools like pandas, seaborn and matplotlib. Ability to work independently and collaboratively within a team. Flexible, adaptive, quick learner."
